{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class GAN_Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, convtrans_channel=[6,3,1], conv_channel=[1,3,6,1],z_dim=64,channel_input=1,bs=128,device='cuda'):\n",
    "        \n",
    "        super(type(self), self).__init__()\n",
    "        self.z_dim=z_dim\n",
    "        self.batch=bs\n",
    "        self.channel=channel_input\n",
    "        self.device=device\n",
    "        \n",
    "        self.generative_layers = torch.nn.Sequential(\n",
    "                                  torch.nn.ConvTranspose2d(self.channel,convtrans_channel[0],4,stride=2,padding=2 ),\n",
    "                                  torch.nn.BatchNorm2d(convtrans_channel[0]),\n",
    "                                  torch.nn.ReLU(True),\n",
    "                                  torch.nn.ConvTranspose2d(convtrans_channel[0],convtrans_channel[1],5,padding=4),\n",
    "                                  torch.nn.BatchNorm2d(convtrans_channel[1]),\n",
    "                                  torch.nn.ReLU(True),\n",
    "                                  torch.nn.ConvTranspose2d(convtrans_channel[1],convtrans_channel[1],5,padding=2),\n",
    "                                  torch.nn.BatchNorm2d(convtrans_channel[1]),\n",
    "                                  torch.nn.ReLU(True),\n",
    "                                  torch.nn.ConvTranspose2d(convtrans_channel[1],convtrans_channel[1],5,padding=2),\n",
    "                                  torch.nn.BatchNorm2d(convtrans_channel[1]),\n",
    "                                  torch.nn.ReLU(True),\n",
    "                                  torch.nn.ConvTranspose2d(convtrans_channel[1],convtrans_channel[2],3,stride=2),\n",
    "                                  #torch.nn.Sigmoid(),\n",
    "                                  #torch.nn.Tanh(),\n",
    "                                  \n",
    "            \n",
    "                                )\n",
    "    \n",
    "\n",
    "                \n",
    "    \n",
    "    def generador(self, z):\n",
    "        z=z.view(-1,self.channel,8,8)\n",
    "        x_falso=self.generative_layers(z)\n",
    "        x_falso=self.normalize(x_falso)\n",
    "        #print(x_falso)\n",
    "        return x_falso\n",
    "            \n",
    "    def sample(self,size):\n",
    "        z=torch.randn(size,self.channel*self.z_dim , device=self.device)\n",
    "        return z\n",
    "    \n",
    "    def normalize(self,x):\n",
    "        im_min = x.min(dim=-1).values.min(dim=-1).values.reshape(-1, 1, 1, 1)\n",
    "        im_max = x.max(dim=-1).values.max(dim=-1).values.reshape(-1, 1, 1, 1)\n",
    "        x = (x - im_min)/(im_max-im_min)\n",
    "        return x\n",
    "       \n",
    "\n",
    "class GAN_Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, convtrans_channel=[6,3,1], conv_channel=[1,3,6,1],z_dim=100,channel_input=1,bs=128,device='cuda'):\n",
    "        \n",
    "        super(type(self), self).__init__()\n",
    "        self.z_dim=z_dim\n",
    "        self.batch=bs\n",
    "        self.channel=channel_input\n",
    "        self.device=device\n",
    "        \n",
    "        ##capas generadoras\n",
    "        self.discriminator_layers= torch.nn.Sequential(\n",
    "                                   torch.nn.Conv2d(conv_channel[0],conv_channel[1],5,stride=2,padding=1),\n",
    "                                   torch.nn.BatchNorm2d(conv_channel[1]),\n",
    "                                   torch.nn.LeakyReLU(0.2),\n",
    "                                   torch.nn.Conv2d(conv_channel[1],conv_channel[2],5,stride=3,padding=1),\n",
    "                                   torch.nn.BatchNorm2d(conv_channel[2]),\n",
    "                                   torch.nn.LeakyReLU(0.2),\n",
    "                                   torch.nn.Conv2d(conv_channel[2],conv_channel[3],5,stride=2,padding=1),\n",
    "                                   torch.nn.Sigmoid(),                                \n",
    "        \n",
    "                                )\n",
    "\n",
    "        \n",
    "    def discriminador(self,supuesto_x):\n",
    "        noise=torch.randn(supuesto_x.shape , device=self.device) ##agregando ruido blanco gaussiano\n",
    "        supuesto_x= torch.clamp(supuesto_x + noise,0.0, 1.0) \n",
    "        supuesto_x=self.discriminator_layers(supuesto_x)\n",
    "        supuesto_x=supuesto_x.view(-1)\n",
    "        return supuesto_x\n",
    "    \n",
    "def loss_disc(disc_datos_xfalso,disc_datos_x,size):\n",
    "    loss=(torch.log(disc_datos_x) + torch.log(1 - disc_datos_xfalso) ).sum() / size\n",
    "    return -loss\n",
    "    \n",
    "def loss_gen(disc_datos_xfalso,size):\n",
    "    loss=torch.log(disc_datos_xfalso).sum() / size\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mimages_test.csv\u001b[0m*  \u001b[01;32mimages_train.csv\u001b[0m*  \u001b[01;32mlabel_test.csv\u001b[0m*  \u001b[01;32mlabel_train.csv\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls /opt/data-nas/HiTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cargamos el CSV de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"/opt/data-nas/HiTS/images_train.csv\",header=None)\n",
    "differences=np.array(df.iloc[:,0:21*21])\n",
    "df=0  ##manera trucha de liberar memoria by javier rojas\n",
    "df=pd.read_csv(\"/opt/data-nas/HiTS/label_train.csv\",header=None)\n",
    "labels=np.array(df)\n",
    "df=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creamos dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'differences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-681f88234da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mastro_image_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mim_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastro_image_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mim_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastro_image_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'differences' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Subset \n",
    "batch_size=128\n",
    "astro_image_tensor=torch.from_numpy(differences.astype('float32')).view(-1,1,21,21)\n",
    "im_min = astro_image_tensor.min(dim=-1).values.min(dim=-1).values.reshape(-1, 1, 1, 1)\n",
    "im_max = astro_image_tensor.max(dim=-1).values.max(dim=-1).values.reshape(-1, 1, 1, 1)\n",
    "astro_image_tensor = (astro_image_tensor - im_min)/(im_max-im_min)\n",
    "\n",
    "astro_dataset = TensorDataset(astro_image_tensor, torch.from_numpy(labels))\n",
    "\n",
    "train_loader = DataLoader(astro_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test section\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "batch_size=32\n",
    "mnist_train_data = torchvision.datasets.MNIST('dataset', train=True, download=True,\n",
    "                                              transform=torchvision.transforms.ToTensor())\n",
    "mnist_test_data = torchvision.datasets.MNIST('dataset', train=False, download=True,\n",
    "                                             transform=torchvision.transforms.ToTensor())\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "np.random.seed(0)\n",
    "#idx = list(range(len(mnist_train_data)))\n",
    "idx = list(range(10000))\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.7*len(idx))\n",
    "\n",
    "train_loader = DataLoader(mnist_train_data, batch_size=batch_size, \n",
    "                          sampler=SubsetRandomSampler(idx[:split]))\n",
    "\n",
    "valid_loader = DataLoader(mnist_train_data, batch_size=batch_size, \n",
    "                          sampler=SubsetRandomSampler(idx[split:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9e24e76ad242afa8a295646b903e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss discriminador: 0.040952  Train loss Generator :0.023764 \n",
      "Train loss discriminador: 0.041626  Train loss Generator :0.023427 \n",
      "Train loss discriminador: 0.043588  Train loss Generator :0.023123 \n",
      "Train loss discriminador: 0.043956  Train loss Generator :0.022845 \n",
      "Train loss discriminador: 0.043085  Train loss Generator :0.023089 \n",
      "Train loss discriminador: 0.042589  Train loss Generator :0.022838 \n",
      "Train loss discriminador: 0.042738  Train loss Generator :0.022167 \n",
      "Train loss discriminador: 0.042190  Train loss Generator :0.022842 \n",
      "Train loss discriminador: 0.043033  Train loss Generator :0.022786 \n",
      "Train loss discriminador: 0.042582  Train loss Generator :0.022620 \n",
      "Train loss discriminador: 0.042376  Train loss Generator :0.022525 \n",
      "Train loss discriminador: 0.042890  Train loss Generator :0.022582 \n",
      "Train loss discriminador: 0.042430  Train loss Generator :0.022966 \n",
      "Train loss discriminador: 0.042304  Train loss Generator :0.022631 \n",
      "Train loss discriminador: 0.042314  Train loss Generator :0.022796 \n",
      "Train loss discriminador: 0.042425  Train loss Generator :0.022949 \n",
      "Train loss discriminador: 0.042488  Train loss Generator :0.022853 \n",
      "Train loss discriminador: 0.042463  Train loss Generator :0.022650 \n",
      "Train loss discriminador: 0.042425  Train loss Generator :0.022861 \n",
      "Train loss discriminador: 0.042403  Train loss Generator :0.023042 \n",
      "Train loss discriminador: 0.042331  Train loss Generator :0.022932 \n",
      "Train loss discriminador: 0.041838  Train loss Generator :0.023116 \n",
      "Train loss discriminador: 0.041992  Train loss Generator :0.023971 \n",
      "Train loss discriminador: 0.042145  Train loss Generator :0.022533 \n",
      "Train loss discriminador: 0.041227  Train loss Generator :0.023977 \n",
      "Train loss discriminador: 0.041432  Train loss Generator :0.024564 \n",
      "Train loss discriminador: 0.042007  Train loss Generator :0.022959 \n",
      "Train loss discriminador: 0.041562  Train loss Generator :0.023964 \n",
      "Train loss discriminador: 0.042094  Train loss Generator :0.023874 \n",
      "Train loss discriminador: 0.040848  Train loss Generator :0.024317 \n",
      "Train loss discriminador: 0.042055  Train loss Generator :0.023514 \n",
      "Train loss discriminador: 0.040561  Train loss Generator :0.024469 \n",
      "Train loss discriminador: 0.041546  Train loss Generator :0.024462 \n",
      "Train loss discriminador: 0.040277  Train loss Generator :0.024614 \n",
      "Train loss discriminador: 0.042071  Train loss Generator :0.024105 \n",
      "Train loss discriminador: 0.039552  Train loss Generator :0.025411 \n",
      "Train loss discriminador: 0.042117  Train loss Generator :0.025084 \n",
      "Train loss discriminador: 0.040186  Train loss Generator :0.025505 \n",
      "Train loss discriminador: 0.040998  Train loss Generator :0.024198 \n",
      "Train loss discriminador: 0.041595  Train loss Generator :0.025293 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-437e7fe8d16d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_disc_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_gen_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m##Para Mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/admin/miniconda3/envs/PT/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "n_epoch=500\n",
    "k_disc=1\n",
    "device='cuda'\n",
    "GEN=GAN_Generator(bs=batch_size).cuda()\n",
    "DISC=GAN_Discriminator(bs=batch_size).cuda()\n",
    "optimizer_gen = torch.optim.Adam(GEN.parameters(), lr=0.0002)\n",
    "optimizer_disc = torch.optim.Adam(DISC.parameters(), lr=0.0002)\n",
    "den = train_loader.__len__()*train_loader.batch_size\n",
    "criterion = torch.nn.BCELoss()\n",
    "global_loss=np.inf\n",
    "for epoch in tqdm_notebook(range(n_epoch)):\n",
    "    for k in range(k_disc):\n",
    "        train_disc_loss=0.0\n",
    "        train_gen_loss=0.0\n",
    "        for image,label in train_loader:\n",
    "            optimizer_disc.zero_grad()  \n",
    "            ##Para Mnist\n",
    "            image=image[:,:,7:28,7:28]\n",
    "            im_min = image.min(dim=-1).values.min(dim=-1).values.reshape(-1, 1, 1, 1)\n",
    "            im_max = image.max(dim=-1).values.max(dim=-1).values.reshape(-1, 1, 1, 1)\n",
    "            image = (image - im_min)/(im_max-im_min)\n",
    "            ##fin de Mnist\n",
    "            image=image.cuda()\n",
    "            \n",
    "            ##Train for real images\n",
    "            output_real = DISC.discriminador(image)#.view(-1)\n",
    "            label = torch.full((image.shape[0],), 1.0, dtype=torch.float, device=image.device)\n",
    "            lossD_real=criterion(output_real,label)\n",
    "            lossD_real.backward()\n",
    "            ##Train disc fake image\n",
    "            label.fill_(0)\n",
    "            fake=GEN.generador(GEN.sample(image.shape[0]))\n",
    "            output_fake_D = DISC.discriminador(fake.detach())#.view(-1)\n",
    "            lossD_fake=criterion(output_fake_D,label)\n",
    "            lossD_fake.backward()\n",
    "            #lossD=loss_disc(output_fake_D,output_real,image.shape[0])\n",
    "            #lossD.backward()\n",
    "            total_loss=lossD_fake + lossD_real\n",
    "            optimizer_disc.step()\n",
    "            #train_disc_loss += lossD.item()\n",
    "            train_disc_loss+=total_loss.item() /den\n",
    "            \n",
    "            ##Train generator\n",
    "            optimizer_gen.zero_grad()  \n",
    "            label.fill_(1) \n",
    "            output=DISC.discriminador(fake)#.view(-1)\n",
    "            lossG=criterion(output,label)\n",
    "            #lossG=loss_gen(output,image.shape[0])\n",
    "            lossG.backward()\n",
    "            #optimizer_disc.step()\n",
    "            optimizer_gen.step()\n",
    "            train_gen_loss+=lossG.item() / den\n",
    "                               \n",
    "                                 \n",
    "            \n",
    "            \n",
    "    print(\"Train loss discriminador: %f  Train loss Generator :%f \"%(train_disc_loss,train_gen_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GAN(device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(lambda p: p.requires_grad, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2fddba3d90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(GEN.generador(GEN.sample(1))[0][0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8446424\n",
      "lo logre\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    kkita=GEN.generador(GEN.sample(1))\n",
    "    kk=DISC.discriminador(kkita).cpu().detach().numpy()[0]\n",
    "    if(kk>0.8):\n",
    "        print(kk)\n",
    "        print(\"lo logre\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2fdeab1c90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(kkita[0][0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-60da212f06f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkita.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
